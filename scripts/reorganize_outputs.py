#!/usr/bin/env python3
"""
é‡æ–°ç»„ç»‡é¡¹ç›®ç›®å½•ç»“æ„
å°†outputsä¸‹çš„æ–‡ä»¶æŒ‰åŠŸèƒ½åˆ†ç±»åˆ°å­ç›®å½•
"""

import os
import shutil
from pathlib import Path
from datetime import datetime


def create_organized_structure():
    """åˆ›å»ºç»„ç»‡è‰¯å¥½çš„ç›®å½•ç»“æ„"""

    base_dir = Path("outputs")

    # å®šä¹‰æ–°çš„ç›®å½•ç»“æ„
    directories = {
        "1_persona_modeling": "Stage 1: Personaå»ºæ¨¡è¾“å‡º",
        "2_data_construction": "Stage 2: è®­ç»ƒæ•°æ®æ„é€ è¾“å‡º",
        "3_training": "Stage 3: æ¨¡å‹è®­ç»ƒè¾“å‡º",
        "4_evaluation": "Stage 4: æ¨¡å‹è¯„ä¼°è¾“å‡º",
        "logs": "è¿è¡Œæ—¥å¿—ï¼ˆæŒ‰æ—¶é—´æˆ³ç»„ç»‡ï¼‰",
    }

    # åˆ›å»ºå­ç›®å½•
    for dir_name, description in directories.items():
        dir_path = base_dir / dir_name
        dir_path.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºREADMEè¯´æ˜
        readme = dir_path / "README.md"
        if not readme.exists():
            readme.write_text(f"# {description}\n\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

        print(f"âœ“ åˆ›å»ºç›®å½•: {dir_path}")

    # åˆ›å»ºè¯„ä¼°å­ç›®å½•
    eval_dir = base_dir / "4_evaluation"
    (eval_dir / "baseline").mkdir(exist_ok=True)
    (eval_dir / "finetuned").mkdir(exist_ok=True)
    print(f"âœ“ åˆ›å»ºè¯„ä¼°å­ç›®å½•")

    return base_dir


def move_files(base_dir):
    """ç§»åŠ¨æ–‡ä»¶åˆ°å¯¹åº”ç›®å½•"""

    # å®šä¹‰æ–‡ä»¶æ˜ å°„ï¼šæºæ–‡ä»¶ -> ç›®æ ‡ç›®å½•
    file_mappings = {
        # Stage 1: Personaå»ºæ¨¡
        "1_persona_modeling": [
            "cleaned_survey_data.csv",
            "preference_factors.csv",
            "factor_loadings.csv",
            "factor_loadings_heatmap.png",
            "personas.json",
            "persona_clustering.png",
            "cluster_distributions.png",
            "persona_types.json",
            "cluster_statistics.json",
        ],

        # Stage 2: æ•°æ®æ„é€ 
        "2_data_construction": [
            "scenarios.json",
            "scenario_statistics.json",
            "decisions.json",
            "decision_statistics.json",
            "train_samples.jsonl",
            "validation_samples.jsonl",
            "sample_statistics.json",
        ],

        # Stage 3: è®­ç»ƒ
        "3_training": [
            "training_curves.png",
        ],

        # Stage 4: è¯„ä¼°
        "4_evaluation": [
            "evaluation_results.json",
        ],

        # Baselineè¯„ä¼°ç»“æœ
        "4_evaluation/baseline": [
            "baseline_results_fixed.json",
            "baseline_test.json",
        ],

        # å¾®è°ƒæ¨¡å‹è¯„ä¼°
        "4_evaluation/finetuned": [
            "checkpoint-2000-results.json",
        ],
    }

    moved_count = 0

    for target_dir, files in file_mappings.items():
        target_path = base_dir / target_dir

        for filename in files:
            source = base_dir / filename
            destination = target_path / filename

            if source.exists():
                # å¦‚æœç›®æ ‡å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³
                if destination.exists():
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    name, ext = os.path.splitext(filename)
                    destination = target_path / f"{name}_{timestamp}{ext}"

                shutil.move(str(source), str(destination))
                print(f"  ç§»åŠ¨: {filename} -> {target_dir}/")
                moved_count += 1
            else:
                print(f"  è·³è¿‡: {filename} (ä¸å­˜åœ¨)")

    print(f"\nâœ“ å…±ç§»åŠ¨ {moved_count} ä¸ªæ–‡ä»¶")


def organize_logs(base_dir):
    """ç»„ç»‡æ—¥å¿—æ–‡ä»¶"""

    logs_source = base_dir / "logs"

    if logs_source.exists():
        log_files = list(logs_source.glob("*.log"))
        print(f"\næ•´ç† {len(log_files)} ä¸ªæ—¥å¿—æ–‡ä»¶...")

        for log_file in log_files:
            # æ—¥å¿—æ–‡ä»¶ä¿æŒåœ¨åŸä½ç½®ï¼Œä½†å¯ä»¥æ·»åŠ è¯´æ˜
            print(f"  ä¿ç•™: logs/{log_file.name}")

    return True


def create_directory_tree(base_dir):
    """åˆ›å»ºç›®å½•æ ‘æ–‡æ¡£"""

    tree_file = base_dir / "DIRECTORY_STRUCTURE.md"

    content = """# è¾“å‡ºç›®å½•ç»“æ„

## ğŸ“ ç›®å½•è¯´æ˜

```
outputs/
â”œâ”€â”€ 1_persona_modeling/          # Stage 1: Personaå»ºæ¨¡
â”‚   â”œâ”€â”€ cleaned_survey_data.csv        # æ¸…æ´—åçš„é—®å·æ•°æ®
â”‚   â”œâ”€â”€ preference_factors.csv         # åå¥½å› å­å¾—åˆ†
â”‚   â”œâ”€â”€ factor_loadings.csv            # å› å­è½½è·çŸ©é˜µ
â”‚   â”œâ”€â”€ factor_loadings_heatmap.png    # å› å­è½½è·çƒ­åŠ›å›¾
â”‚   â”œâ”€â”€ personas.json                  # ç”Ÿæˆçš„personas
â”‚   â”œâ”€â”€ persona_clustering.png         # èšç±»å¯è§†åŒ–
â”‚   â”œâ”€â”€ cluster_distributions.png      # èšç±»åˆ†å¸ƒ
â”‚   â”œâ”€â”€ persona_types.json             # Personaç±»å‹å®šä¹‰
â”‚   â””â”€â”€ cluster_statistics.json        # èšç±»ç»Ÿè®¡
â”‚
â”œâ”€â”€ 2_data_construction/         # Stage 2: è®­ç»ƒæ•°æ®æ„é€ 
â”‚   â”œâ”€â”€ scenarios.json                 # ç”Ÿæˆçš„åœºæ™¯
â”‚   â”œâ”€â”€ scenario_statistics.json       # åœºæ™¯ç»Ÿè®¡
â”‚   â”œâ”€â”€ decisions.json                 # æ¨¡æ‹Ÿçš„å†³ç­–
â”‚   â”œâ”€â”€ decision_statistics.json       # å†³ç­–ç»Ÿè®¡
â”‚   â”œâ”€â”€ train_samples.jsonl            # è®­ç»ƒæ ·æœ¬
â”‚   â”œâ”€â”€ validation_samples.jsonl       # éªŒè¯æ ·æœ¬
â”‚   â””â”€â”€ sample_statistics.json         # æ ·æœ¬ç»Ÿè®¡
â”‚
â”œâ”€â”€ 3_training/                  # Stage 3: æ¨¡å‹è®­ç»ƒ
â”‚   â”œâ”€â”€ runs/                          # TensorBoardæ—¥å¿—
â”‚   â”‚   â””â”€â”€ run_YYYYMMDD_HHMMSS/      # æŒ‰æ—¶é—´æˆ³ç»„ç»‡çš„è®­ç»ƒè¿è¡Œ
â”‚   â””â”€â”€ training_curves.png            # è®­ç»ƒæ›²çº¿å¯è§†åŒ–
â”‚
â”œâ”€â”€ 4_evaluation/                # Stage 4: æ¨¡å‹è¯„ä¼°
â”‚   â”œâ”€â”€ baseline/                      # Baselineæ¨¡å‹è¯„ä¼°
â”‚   â”‚   â”œâ”€â”€ baseline_results_*.json
â”‚   â”‚   â””â”€â”€ baseline_test.json
â”‚   â”œâ”€â”€ finetuned/                     # å¾®è°ƒæ¨¡å‹è¯„ä¼°
â”‚   â”‚   â””â”€â”€ checkpoint-*_results.json
â”‚   â””â”€â”€ evaluation_results.json        # æœ€æ–°è¯„ä¼°ç»“æœ
â”‚
â””â”€â”€ logs/                        # è¿è¡Œæ—¥å¿—
    â”œâ”€â”€ persona_modeling_*.log         # Personaå»ºæ¨¡æ—¥å¿—
    â”œâ”€â”€ data_construction_*.log        # æ•°æ®æ„é€ æ—¥å¿—
    â”œâ”€â”€ training_*.log                 # è®­ç»ƒæ—¥å¿—
    â””â”€â”€ evaluation_*.log               # è¯„ä¼°æ—¥å¿—
```

## ğŸ”„ æ–‡ä»¶å‘½åè§„èŒƒ

### æ—¶é—´æˆ³æ ¼å¼
- æ—¥å¿—æ–‡ä»¶: `MODULE_YYYYMMDD_HHMMSS.log`
- è¯„ä¼°ç»“æœ: `MODEL_YYYYMMDD_HHMMSS.json`
- è®­ç»ƒè¿è¡Œ: `run_YYYYMMDD_HHMMSS/`

### ç¤ºä¾‹
```
logs/training_20241210_205243.log
4_evaluation/finetuned/checkpoint-2000_20241210_204530.json
3_training/runs/run_20241210_205243/
```

## ğŸ“ ä½¿ç”¨è¯´æ˜

1. **Stage 1-2**: è¾“å‡ºæ–‡ä»¶è‡ªåŠ¨ä¿å­˜åˆ°å¯¹åº”ç›®å½•
2. **Stage 3**: è®­ç»ƒæ—¥å¿—æŒ‰æ—¶é—´æˆ³è‡ªåŠ¨åˆ›å»ºæ–°ç›®å½•
3. **Stage 4**: è¯„ä¼°ç»“æœæŒ‰æ¨¡å‹ç±»å‹åˆ†ç±»ä¿å­˜

## ğŸ”§ é…ç½®æ–‡ä»¶

ä¸»è¦é…ç½®æ–‡ä»¶ï¼š`configs/training_config.yaml`

å…³é”®è·¯å¾„è®¾ç½®ï¼š
```yaml
paths:
  persona_output_dir: "outputs/1_persona_modeling"
  data_output_dir: "outputs/2_data_construction"
  training_output_dir: "outputs/3_training"
  eval_output_dir: "outputs/4_evaluation"
  logs_dir: "outputs/logs"
```

---

ç”Ÿæˆæ—¶é—´: {timestamp}
    """.format(timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'))

    tree_file.write_text(content)
    print(f"\nâœ“ åˆ›å»ºç›®å½•ç»“æ„æ–‡æ¡£: {tree_file}")


def main():
    print("=" * 80)
    print("é‡æ–°ç»„ç»‡é¡¹ç›®ç›®å½•ç»“æ„")
    print("=" * 80)

    # 1. åˆ›å»ºç›®å½•ç»“æ„
    print("\n[1/4] åˆ›å»ºæ–°ç›®å½•ç»“æ„...")
    base_dir = create_organized_structure()

    # 2. ç§»åŠ¨æ–‡ä»¶
    print("\n[2/4] ç§»åŠ¨ç°æœ‰æ–‡ä»¶åˆ°å¯¹åº”ç›®å½•...")
    move_files(base_dir)

    # 3. æ•´ç†æ—¥å¿—
    print("\n[3/4] æ•´ç†æ—¥å¿—æ–‡ä»¶...")
    organize_logs(base_dir)

    # 4. åˆ›å»ºæ–‡æ¡£
    print("\n[4/4] åˆ›å»ºç›®å½•ç»“æ„æ–‡æ¡£...")
    create_directory_tree(base_dir)

    print("\n" + "=" * 80)
    print("âœ“ ç›®å½•é‡ç»„å®Œæˆï¼")
    print("=" * 80)
    print("\næŸ¥çœ‹æ–°çš„ç›®å½•ç»“æ„:")
    print("  cat outputs/DIRECTORY_STRUCTURE.md")
    print("\næˆ–è€…:")
    print("  tree outputs/ -L 2")


if __name__ == "__main__":
    main()
