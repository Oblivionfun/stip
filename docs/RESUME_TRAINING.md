# ä»Checkpointæ¢å¤è®­ç»ƒ

## ğŸ“‹ æ¦‚è¿°

å½“è®­ç»ƒä¸­æ–­æˆ–è€…æƒ³è¦ç»§ç»­è®­ç»ƒæ›´å¤šepochsæ—¶ï¼Œå¯ä»¥ä»ä¹‹å‰ä¿å­˜çš„checkpointæ¢å¤è®­ç»ƒã€‚

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. æŸ¥çœ‹å¯ç”¨çš„Checkpoint

```bash
ls -lh checkpoints/sft_model/
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
checkpoint-1000/
checkpoint-1500/
checkpoint-2000/  â† æœ€æ–°çš„checkpoint
```

### 2. æ£€æŸ¥Checkpointçš„è®­ç»ƒè¿›åº¦

```bash
python3 -c "
import json
data = json.load(open('checkpoints/sft_model/checkpoint-2000/trainer_state.json'))
print(f'å½“å‰æ­¥æ•°: {data[\"global_step\"]}')
print(f'å½“å‰epoch: {data[\"epoch\"]:.2f}')
print(f'è®­ç»ƒè¿›åº¦: {data[\"epoch\"]/3.0*100:.1f}%')
"
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
å½“å‰æ­¥æ•°: 2000
å½“å‰epoch: 1.77
è®­ç»ƒè¿›åº¦: 59.1%
```

### 3. ä»Checkpointæ¢å¤è®­ç»ƒ

**åŸºæœ¬ç”¨æ³•ï¼š**
```bash
python run_model_training.py --resume checkpoints/sft_model/checkpoint-2000 -y
```

**å®Œæ•´å‚æ•°ï¼š**
```bash
python run_model_training.py \
  --resume checkpoints/sft_model/checkpoint-2000 \
  --no-unsloth \  # å¯é€‰ï¼šä¸ä½¿ç”¨unslothåŠ é€Ÿ
  -y              # å¯é€‰ï¼šè·³è¿‡ç¡®è®¤æç¤º
```

## ğŸ“Š æ¢å¤è®­ç»ƒçš„ç‰¹ç‚¹

### âœ… ä¼šä¿ç•™çš„çŠ¶æ€
- âœ… **æ¨¡å‹æƒé‡**ï¼šLoRAé€‚é…å™¨å‚æ•°
- âœ… **ä¼˜åŒ–å™¨çŠ¶æ€**ï¼šAdamçš„momentumç­‰
- âœ… **å­¦ä¹ ç‡è°ƒåº¦**ï¼šwarmupå’Œdecayçš„å½“å‰çŠ¶æ€
- âœ… **è®­ç»ƒæ­¥æ•°**ï¼šä»checkpointçš„æ­¥æ•°ç»§ç»­
- âœ… **éšæœºæ•°çŠ¶æ€**ï¼šç¡®ä¿å¯é‡å¤æ€§

### ğŸ“ Checkpointå†…å®¹
```
checkpoint-2000/
â”œâ”€â”€ adapter_model.safetensors  # LoRAæƒé‡
â”œâ”€â”€ optimizer.pt               # ä¼˜åŒ–å™¨çŠ¶æ€
â”œâ”€â”€ scheduler.pt               # å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€
â”œâ”€â”€ trainer_state.json         # è®­ç»ƒçŠ¶æ€ï¼ˆæ­¥æ•°ã€epochç­‰ï¼‰
â”œâ”€â”€ training_args.bin          # è®­ç»ƒå‚æ•°
â””â”€â”€ rng_state.pth             # éšæœºæ•°ç”Ÿæˆå™¨çŠ¶æ€
```

## ğŸ”„ è®­ç»ƒæµç¨‹

### ä»å¤´å¼€å§‹è®­ç»ƒ
```bash
python run_model_training.py -y
```
- ä»åŸºç¡€æ¨¡å‹ `model/models` å¼€å§‹
- Step: 0 â†’ 3000 (å‡è®¾3 epochs)
- Epoch: 0.0 â†’ 3.0

### ä»Checkpointæ¢å¤
```bash
python run_model_training.py --resume checkpoints/sft_model/checkpoint-2000 -y
```
- ä»checkpoint-2000æ¢å¤
- Step: 2000 â†’ 3000
- Epoch: 1.77 â†’ 3.0

## ğŸ“ˆ ç›‘æ§è®­ç»ƒ

### TensorBoard
```bash
# æŸ¥çœ‹æ‰€æœ‰è®­ç»ƒè¿è¡Œï¼ˆåŒ…æ‹¬æ¢å¤çš„è®­ç»ƒï¼‰
tensorboard --logdir outputs/3_training/runs --port 6006 --bind_all
```

**æ³¨æ„ï¼š** æ¢å¤è®­ç»ƒä¼šåˆ›å»ºæ–°çš„TensorBoardæ—¥å¿—ç›®å½•ï¼ˆå¸¦æ–°æ—¶é—´æˆ³ï¼‰ï¼Œä½†è®­ç»ƒæ­¥æ•°ä¼šä»checkpointçš„æ­¥æ•°ç»§ç»­ã€‚

### æŸ¥çœ‹æ—¥å¿—
```bash
# æŸ¥çœ‹æœ€æ–°çš„è®­ç»ƒæ—¥å¿—
ls -t outputs/logs/sft_trainer_*.log | head -1 | xargs tail -f
```

## ğŸ’¡ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šè®­ç»ƒä¸­æ–­
```bash
# è®­ç»ƒåœ¨step 2000æ—¶ä¸­æ–­
# ç›´æ¥ä»æœ€æ–°checkpointæ¢å¤
python run_model_training.py --resume checkpoints/sft_model/checkpoint-2000 -y
```

### åœºæ™¯2ï¼šæƒ³è¦è®­ç»ƒæ›´å¤šepochs
```bash
# 1. ä¿®æ”¹é…ç½®æ–‡ä»¶å¢åŠ epochs
vim configs/training_config.yaml
# å°† num_train_epochs: 3 æ”¹ä¸º num_train_epochs: 5

# 2. ä»checkpointæ¢å¤ï¼Œç»§ç»­è®­ç»ƒ
python run_model_training.py --resume checkpoints/sft_model/checkpoint-2000 -y
```

### åœºæ™¯3ï¼šè°ƒæ•´å­¦ä¹ ç‡ç»§ç»­è®­ç»ƒ
```bash
# 1. ä¿®æ”¹é…ç½®æ–‡ä»¶é™ä½å­¦ä¹ ç‡
vim configs/training_config.yaml
# å°† learning_rate: 2.0e-4 æ”¹ä¸º learning_rate: 1.0e-4

# 2. ä»checkpointæ¢å¤
python run_model_training.py --resume checkpoints/sft_model/checkpoint-2000 -y
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. é…ç½®ä¸€è‡´æ€§
æ¢å¤è®­ç»ƒæ—¶ï¼Œå¤§éƒ¨åˆ†è®­ç»ƒé…ç½®ä¼šä»checkpointä¸­çš„ `training_args.bin` æ¢å¤ã€‚ä½†æŸäº›é…ç½®ä¼šä½¿ç”¨æ–°çš„å€¼ï¼š
- âœ… å¯ä»¥ä¿®æ”¹ï¼š`num_train_epochs`, `learning_rate`, `logging_steps`
- âŒ ä¸å»ºè®®ä¿®æ”¹ï¼š`batch_size`, `model_name`, `max_seq_length`

### 2. æ•°æ®ä¸€è‡´æ€§
- ç¡®ä¿è®­ç»ƒæ•°æ®æ–‡ä»¶æ²¡æœ‰æ”¹å˜
- å¦‚æœæ•°æ®æ”¹å˜ï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®š

### 3. Checkpointå®Œæ•´æ€§
ç¡®ä¿checkpointç›®å½•å®Œæ•´ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦æ–‡ä»¶ï¼š
```bash
ls checkpoints/sft_model/checkpoint-2000/
# åº”è¯¥çœ‹åˆ°ï¼šadapter_model.safetensors, optimizer.pt, scheduler.ptç­‰
```

### 4. ç£ç›˜ç©ºé—´
- æ¯ä¸ªcheckpointçº¦260MB
- ç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´ä¿å­˜æ–°çš„checkpoint

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜1ï¼šæ‰¾ä¸åˆ°checkpoint
```
Error: [Errno 2] No such file or directory: 'checkpoints/sft_model/checkpoint-2000'
```

**è§£å†³ï¼š**
```bash
# æ£€æŸ¥checkpointæ˜¯å¦å­˜åœ¨
ls -lh checkpoints/sft_model/
# ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
```

### é—®é¢˜2ï¼šé…ç½®ä¸åŒ¹é…
```
ValueError: The model is not compatible with the checkpoint
```

**è§£å†³ï¼š**
- ä¸è¦ä¿®æ”¹æ¨¡å‹æ¶æ„ç›¸å…³é…ç½®ï¼ˆmax_seq_length, dtypeç­‰ï¼‰
- ç¡®ä¿ä½¿ç”¨ç›¸åŒçš„åŸºç¡€æ¨¡å‹è·¯å¾„

### é—®é¢˜3ï¼šæ˜¾å­˜ä¸è¶³
```
RuntimeError: CUDA out of memory
```

**è§£å†³ï¼š**
```bash
# ä½¿ç”¨ç›¸åŒçš„batch sizeå’Œgradient accumulation
# æˆ–è€…å‡å°batch sizeï¼ˆä½†å¯èƒ½å½±å“è®­ç»ƒæ•ˆæœï¼‰
```

## ğŸ“š å‚è€ƒå‘½ä»¤æ±‡æ€»

```bash
# æŸ¥çœ‹checkpointåˆ—è¡¨
ls -lh checkpoints/sft_model/

# æŸ¥çœ‹è®­ç»ƒè¿›åº¦
python3 -c "import json; print(json.load(open('checkpoints/sft_model/checkpoint-2000/trainer_state.json'))['epoch'])"

# ä»checkpointæ¢å¤è®­ç»ƒï¼ˆæ¨èï¼‰
python run_model_training.py --resume checkpoints/sft_model/checkpoint-2000 -y

# ä»å¤´å¼€å§‹è®­ç»ƒï¼ˆå¯¹æ¯”ï¼‰
python run_model_training.py -y

# æŸ¥çœ‹TensorBoard
tensorboard --logdir outputs/3_training/runs --port 6006 --bind_all

# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
ls -t outputs/logs/sft_trainer_*.log | head -1 | xargs tail -f
```

---

æœ€åæ›´æ–°: 2024-12-10
